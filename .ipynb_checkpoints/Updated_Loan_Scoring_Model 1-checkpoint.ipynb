{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba12850",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.utils import resample\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2937cb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the data\n",
    "file_paths = [\n",
    "    '/mnt/data/Test data.xlsx - Query result.csv',\n",
    "    '/mnt/data/Model test data.csv',\n",
    "    '/mnt/data/Loan Status prediction data.xlsx - Query result.csv'\n",
    "]\n",
    "\n",
    "data_frames = []\n",
    "for file_path in file_paths:\n",
    "    df = pd.read_csv(file_path, encoding='ISO-8859-1')\n",
    "    data_frames.append(df)\n",
    "\n",
    "# Select one of the DataFrames to work with, e.g., DataFrame 1\n",
    "df = data_frames[0]\n",
    "\n",
    "# Fill missing values for simplicity, here with mode for categorical and median for numerical\n",
    "for column in df.select_dtypes(include=['object']).columns:\n",
    "    df[column].fillna(df[column].mode()[0], inplace=True)\n",
    "\n",
    "for column in df.select_dtypes(include=[np.number]).columns:\n",
    "    df[column].fillna(df[column].median(), inplace=True)\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "for column in df.select_dtypes(include=['object']).columns:\n",
    "    le = LabelEncoder()\n",
    "    df[column] = le.fit_transform(df[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Split the data into features and target\n",
    "X = df.drop(columns=['status_id'])\n",
    "y = df['status_id']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adff5246",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Handle class imbalance using undersampling\n",
    "train_data = pd.concat([pd.DataFrame(X_train_scaled), pd.Series(y_train, name='label')], axis=1)\n",
    "\n",
    "# Separate the majority and minority classes\n",
    "majority_class = train_data[train_data['label'] == 2]\n",
    "minority_class = train_data[train_data['label'] == 5]\n",
    "\n",
    "# Undersample the majority class\n",
    "majority_class_undersampled = resample(majority_class, \n",
    "                                       replace=False,    # sample without replacement\n",
    "                                       n_samples=len(minority_class),     # match minority class count\n",
    "                                       random_state=42)   # reproducible results\n",
    "\n",
    "# Combine the undersampled majority class with the minority class\n",
    "undersampled_data = pd.concat([majority_class_undersampled, minority_class])\n",
    "\n",
    "# Separate the features and labels\n",
    "X_train_undersampled = undersampled_data.drop(columns='label')\n",
    "y_train_undersampled = undersampled_data['label']\n",
    "\n",
    "# Handle missing values in the undersampled dataset\n",
    "for column in X_train_undersampled.select_dtypes(include=['object']).columns:\n",
    "    X_train_undersampled[column].fillna(X_train_undersampled[column].mode()[0], inplace=True)\n",
    "\n",
    "for column in X_train_undersampled.select_dtypes(include=[np.number]).columns:\n",
    "    X_train_undersampled[column].fillna(X_train_undersampled[column].median(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd45801",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train the logistic regression model with undersampled data\n",
    "logistic_model_undersampled = LogisticRegression(max_iter=1000)\n",
    "logistic_model_undersampled.fit(X_train_undersampled, y_train_undersampled)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_logistic_undersampled = logistic_model_undersampled.predict(X_test_scaled)\n",
    "\n",
    "# Map the predictions to 'Paid' and 'Unpaid'\n",
    "prediction_mapping = {2: 'Paid', 5: 'Unpaid'}\n",
    "y_pred_logistic_undersampled_mapped = [prediction_mapping.get(pred, 'Unpaid') for pred in y_pred_logistic_undersampled]\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_logistic_undersampled = accuracy_score(y_test.map(prediction_mapping), y_pred_logistic_undersampled_mapped)\n",
    "classification_report_logistic_undersampled = classification_report(y_test.map(prediction_mapping), y_pred_logistic_undersampled_mapped, labels=['Paid', 'Unpaid'])\n",
    "\n",
    "print(f\"Logistic Regression Model (Undersampled)\n",
    "Accuracy: {accuracy_logistic_undersampled}\n",
    "\")\n",
    "print(classification_report_logistic_undersampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1de13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train the XGBoost model with undersampled data\n",
    "xgb_model_undersampled = XGBClassifier(n_estimators=50, max_depth=2, learning_rate=0.2, use_label_encoder=False, eval_metric='mlogloss')\n",
    "xgb_model_undersampled.fit(X_train_undersampled, y_train_undersampled)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_xgb_undersampled = xgb_model_undersampled.predict(X_test_scaled)\n",
    "\n",
    "# Map the predictions to 'Paid' and 'Unpaid'\n",
    "y_pred_xgb_undersampled_mapped = [prediction_mapping.get(pred, 'Unpaid') for pred in y_pred_xgb_undersampled]\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_xgb_undersampled = accuracy_score(y_test.map(prediction_mapping), y_pred_xgb_undersampled_mapped)\n",
    "classification_report_xgb_undersampled = classification_report(y_test.map(prediction_mapping), y_pred_xgb_undersampled_mapped, labels=['Paid', 'Unpaid'])\n",
    "\n",
    "print(f\"XGBoost Model (Undersampled)\n",
    "Accuracy: {accuracy_xgb_undersampled}\n",
    "\")\n",
    "print(classification_report_xgb_undersampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7602efe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the updated logistic regression model (undersampled)\n",
    "logistic_model_undersampled_path = 'logistic_regression_model_undersampled.pkl'\n",
    "with open(logistic_model_undersampled_path, 'wb') as file:\n",
    "    pickle.dump(logistic_model_undersampled, file)\n",
    "\n",
    "# Save the updated XGBoost model (undersampled)\n",
    "xgb_model_undersampled_path = 'xgboost_model_undersampled.pkl'\n",
    "with open(xgb_model_undersampled_path, 'wb') as file:\n",
    "    pickle.dump(xgb_model_undersampled, file)\n",
    "\n",
    "logistic_model_undersampled_path, xgb_model_undersampled_path\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
